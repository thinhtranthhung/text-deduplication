"""
Module t√¨m ki·∫øm tr√πng l·∫∑p s·ª≠ d·ª•ng FAISS
"""
import numpy as np
import faiss
from typing import List, Tuple


def find_duplicates_faiss(
    embeddings: np.ndarray,
    top_k: int = 5,
    similarity_threshold: float = 0.85
) -> List[Tuple[int, int, float]]:
    """
    T√¨m c√°c c·∫∑p vƒÉn b·∫£n t∆∞∆°ng t·ª± s·ª≠ d·ª•ng FAISS
    
    Args:
        embeddings: numpy array shape (n_docs, embedding_dim) - float32
        top_k: S·ªë l√°ng gi·ªÅng g·∫ßn nh·∫•t ƒë·ªÉ ki·ªÉm tra
        similarity_threshold: Ng∆∞·ª°ng cosine similarity
    
    Returns:
        List c√°c tuple (doc_id_1, doc_id_2, similarity_score)
    """
    
    if embeddings is None or embeddings.size == 0:
        print("‚ö†Ô∏è  Embeddings tr·ªëng")
        return []
    
    n_docs, embedding_dim = embeddings.shape
    print(f"üîç FAISS: T√¨m ki·∫øm tr√πng l·∫∑p trong {n_docs} vƒÉn b·∫£n (dim={embedding_dim})")
    
    # Copy embeddings ƒë·ªÉ kh√¥ng thay ƒë·ªïi original
    embeddings_copy = embeddings.copy().astype(np.float32)
    
    # Normalize cho inner product = cosine similarity
    faiss.normalize_L2(embeddings_copy)
    
    # T·∫°o index
    index = faiss.IndexFlatIP(embedding_dim)
    index.add(embeddings_copy)
    
    # Search
    distances, indices = index.search(embeddings_copy, min(top_k, n_docs))
    
    # L·∫•y k·∫øt qu·∫£
    similar_pairs = set()
    results = []
    
    for i in range(n_docs):
        for rank in range(1, min(top_k, len(indices[i]))):
            j = int(indices[i][rank])
            
            # B·ªè qua self-comparison ho·∫∑c k·∫øt qu·∫£ kh√¥ng h·ª£p l·ªá
            if j == -1 or i == j:
                continue
            
            sim_score = float(distances[i][rank])
            
            # Ch·ªâ gi·ªØ c·∫∑p v∆∞·ª£t ng∆∞·ª°ng
            if sim_score >= similarity_threshold:
                pair = tuple(sorted([i, j]))
                
                if pair not in similar_pairs:
                    similar_pairs.add(pair)
                    results.append((pair[0], pair[1], sim_score))
    
    # S·∫Øp x·∫øp theo similarity gi·∫£m d·∫ßn
    results.sort(key=lambda x: x[2], reverse=True)
    
    print(f"‚úì T√¨m ƒë∆∞·ª£c {len(results)} c·∫∑p t∆∞∆°ng t·ª± (ng∆∞·ª°ng: {similarity_threshold})")
    return results


if __name__ == '__main__':
    # Test
    from embedding import get_embeddings_from_texts
    
    test_texts = [
        "Vi·ªát Nam l√† m·ªôt n∆∞·ªõc x√£ h·ªôi ch·ªß nghƒ©a",
        "Vi·ªát Nam l√† m·ªôt n∆∞·ªõc x√£ h·ªôi ch·ªß nghƒ©a v·ªõi th·ªß ƒë√¥ H√† N·ªôi",
        "H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam",
        "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn",
    ]
    
    embeddings = get_embeddings_from_texts(test_texts)
    results = find_duplicates_faiss(embeddings, similarity_threshold=0.7)
    
    print("\nK·∫øt qu·∫£:")
    for i, j, sim in results:
        print(f"  ({i}, {j}): {sim:.4f} - '{test_texts[i][:50]}...' <-> '{test_texts[j][:50]}...'")