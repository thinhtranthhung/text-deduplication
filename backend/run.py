"""
Backend ch√≠nh - Flask API x·ª≠ l√Ω ph√°t hi·ªán tr√πng l·∫∑p
"""
import os
import time
from io import BytesIO
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from werkzeug.utils import secure_filename
import numpy as np

# Import c√°c module x·ª≠ l√Ω
from utils import extract_text_from_file
from embedding import get_embeddings_from_texts
from simhash import find_duplicates_simhash
from minhash import find_duplicates_minhash
from faiss_search import find_duplicates_faiss
from clustering import process_clustering
from export_word import create_deduplication_report

# ===== SETUP FLASK =====
app = Flask(__name__)
CORS(app)

# Config
UPLOAD_FOLDER = 'uploads'
OUTPUT_FOLDER = 'output_docs'
ALLOWED_EXTENSIONS = {'txt', 'csv', 'json', 'doc', 'docx'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = MAX_FILE_SIZE

# Global cache ƒë·ªÉ l∆∞u file t·∫°o ra
generated_files = {}


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


# ===== API ENDPOINTS =====

@app.route('/api/health', methods=['GET'])
def health_check():
    """Ki·ªÉm tra backend c√≥ ch·∫°y kh√¥ng"""
    return jsonify({
        'status': 'ok',
        'message': 'Backend is running',
        'version': '1.0.0'
    })


@app.route('/api/process', methods=['POST'])
def process_file():
    """
    Endpoint ch√≠nh: upload file ‚Üí embedding ‚Üí dedup ‚Üí clustering ‚Üí export docx
    """
    
    start_time = time.time()
    
    try:
        # ===== B∆Ø·ªöC 1: KI·ªÇM TRA FILE =====
        if 'file' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c upload'}), 400
        
        file = request.files['file']
        method = request.form.get('method', 'all')
        
        if file.filename == '' or not allowed_file(file.filename):
            return jsonify({
                'error': f'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ h·ªó tr·ª£: {", ".join(ALLOWED_EXTENSIONS)}'
            }), 400
        
        print(f"\n{'='*60}")
        print(f"üì• Nh·∫≠n file: {file.filename}")
        print(f"{'='*60}")
        
        # ===== B∆Ø·ªöC 2: ƒê·ªåC N·ªòI DUNG FILE =====
        try:
            texts = extract_text_from_file(file)
        except Exception as e:
            return jsonify({'error': f'L·ªói ƒë·ªçc file: {str(e)}'}), 400
        
        if len(texts) < 2:
            return jsonify({'error': f'File ph·∫£i ch·ª©a √≠t nh·∫•t 2 vƒÉn b·∫£n (hi·ªán c√≥ {len(texts)})'}), 400
        
        # ===== B∆Ø·ªöC 3: T·∫†O EMBEDDINGS =====
        print(f"\nüìä B∆∞·ªõc 1/4: T·∫°o Embeddings")
        print(f"{'='*60}")
        
        try:
            embeddings = get_embeddings_from_texts(texts, batch_size=32)
            embeddings = embeddings.astype(np.float32)
        except Exception as e:
            return jsonify({'error': f'L·ªói t·∫°o embedding: {str(e)}'}), 500
        
        # ===== B∆Ø·ªöC 4: PH√ÅT HI·ªÜN TR√ôNG L·∫∂P =====
        print(f"\nüîç B∆∞·ªõc 2/4: Ph√°t Hi·ªán Tr√πng L·∫∑p")
        print(f"{'='*60}")
        
        methods_to_run = {}
        
        if method == 'all':
            methods_to_run = {
                'simhash': 'SimHash',
                'minhash': 'MinHash',
                'faiss': 'FAISS'
            }
        else:
            method_names = {
                'simhash': 'SimHash',
                'minhash': 'MinHash',
                'faiss': 'FAISS'
            }
            methods_to_run = {method: method_names.get(method, method)}
        
        results = {}
        word_files = []
        
        for method_key, method_name in methods_to_run.items():
            try:
                # Ph√°t hi·ªán tr√πng l·∫∑p theo ph∆∞∆°ng ph√°p
                if method_key == 'faiss':
                    pairs = find_duplicates_faiss(embeddings, top_k=5, similarity_threshold=0.85)
                
                elif method_key == 'simhash':
                    pairs = find_duplicates_simhash(embeddings, nbits=128, bands=8, hamming_threshold=15)
                
                elif method_key == 'minhash':
                    pairs = find_duplicates_minhash(texts, num_perm=128, jaccard_threshold=0.5)
                
                else:
                    raise ValueError(f"Ph∆∞∆°ng ph√°p '{method_key}' kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£")
                
                # ===== B∆Ø·ªöC 5: PH√ÇN C·ª§M =====
                print(f"\nüîó B∆∞·ªõc 3/4: Ph√¢n C·ª•m ({method_name})")
                print(f"{'='*60}")
                
                clustering_result = process_clustering(
                    pairs,
                    texts,
                    embeddings,
                    representative_method='centroid'
                )
                
                # ===== B∆Ø·ªöC 6: XU·∫§T DOCX =====
                print(f"\nüìÑ B∆∞·ªõc 4/4: Xu·∫•t B√°o C√°o ({method_name})")
                print(f"{'='*60}")
                
                # T·∫°o t√™n file
                timestamp = int(time.time())
                doc_filename = f"report_{method_key}_{timestamp}.docx"
                doc_path = os.path.join(OUTPUT_FOLDER, doc_filename)
                
                # Chu·∫©n b·ªã performance data
                elapsed_time = time.time() - start_time
                performance = {
                    'Ph∆∞∆°ng ph√°p': method_name,
                    'Th·ªùi gian x·ª≠ l√Ω': f"{elapsed_time:.2f}s",
                    'S·ªë vƒÉn b·∫£n': f"{len(texts)} vƒÉn b·∫£n",
                    'S·ªë c·∫∑p t∆∞∆°ng t·ª±': f"{len(pairs)} c·∫∑p"
                }
                
                # Xu·∫•t Word
                create_deduplication_report(
                    clustering_result,
                    method_name,
                    doc_path,
                    performance
                )
                
                word_files.append(doc_filename)
                generated_files[doc_filename] = doc_path
                
                # Chu·∫©n b·ªã k·∫øt qu·∫£ tr·∫£ v·ªÅ
                results[method_name] = {
                    'success': True,
                    'stats': clustering_result['stats'],
                    'clusters': clustering_result['clusters'],
                    'performance': performance
                }
                
                print(f"‚úì {method_name} x·ª≠ l√Ω th√†nh c√¥ng")
            
            except Exception as e:
                print(f"‚ùå L·ªói v·ªõi {method_name}: {str(e)}")
                results[method_name] = {'error': str(e)}
        
        # ===== TR·∫¢ V·ªÄ K·∫æT QU·∫¢ =====
        print(f"\n{'='*60}")
        print(f"‚úì X·ª¨ L√ù HO√ÄN TH√ÄNH")
        print(f"{'='*60}\n")
        
        return jsonify({
            'success': True,
            'methods': results,
            'word_files': word_files,
            'timestamp': timestamp
        })
    
    except Exception as e:
        print(f"\n‚ùå L·ªói backend: {str(e)}")
        return jsonify({'error': f'L·ªói server: {str(e)}'}), 500


@app.route('/api/download/<filename>', methods=['GET'])
def download_file(filename):
    """Download file b√°o c√°o Word"""
    try:
        if filename not in generated_files:
            return jsonify({'error': 'File kh√¥ng t·ªìn t·∫°i'}), 404
        
        file_path = generated_files[filename]
        
        if not os.path.exists(file_path):
            return jsonify({'error': 'File kh√¥ng t√¨m th·∫•y'}), 404
        
        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        )
    
    except Exception as e:
        return jsonify({'error': f'L·ªói download: {str(e)}'}), 500


# ===== ERROR HANDLERS =====

@app.errorhandler(413)
def request_entity_too_large(error):
    return jsonify({'error': 'File qu√° l·ªõn (t·ªëi ƒëa 50MB)'}), 413


@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'L·ªói server n·ªôi b·ªô'}), 500


@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint kh√¥ng t√¨m th·∫•y'}), 404


# ===== MAIN =====

if __name__ == '__main__':
    print("\n" + "="*60)
    print("üöÄ KH·ªûI ƒê·ªòNG SERVER PH√ÅT HI·ªÜN TR√ôNG L·∫∂P VƒÇN B·∫¢N")
    print("="*60)
    print(f"üìç Backend: http://localhost:5000")
    print(f"üìç API Base: http://localhost:5000/api")
    print(f"üìç Health Check: http://localhost:5000/api/health")
    print("="*60 + "\n")
    
    app.run(
        debug=True,
        host='0.0.0.0',
        port=5000,
        use_reloader=False  # T·∫Øt reloader ƒë·ªÉ tr√°nh l·ªói multi-processing
    )