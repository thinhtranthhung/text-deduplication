"""
Module t√¨m ki·∫øm tr√πng l·∫∑p s·ª≠ d·ª•ng MinHash + LSH
"""
import re
from typing import List, Tuple
from tqdm import tqdm
from datasketch import MinHash, MinHashLSH


def create_shingles(text: str, k: int = 5) -> set:
    """
    T·∫°o k-shingles t·ª´ text
    
    Args:
        text: VƒÉn b·∫£n ƒë·∫ßu v√†o
        k: K√≠ch th∆∞·ªõc shingle
    
    Returns:
        Set c√°c shingle
    """
    # Normalize text
    text = re.sub(r'\s+', ' ', text.lower().strip())
    
    if len(text) < k:
        return {text}
    
    shingles = set()
    for i in range(len(text) - k + 1):
        shingles.add(text[i:i+k])
    
    return shingles


def find_duplicates_minhash(
    texts: List[str],
    num_perm: int = 128,
    jaccard_threshold: float = 0.5,
    k_shingles: int = 5
) -> List[Tuple[int, int, float]]:
    """
    T√¨m c√°c c·∫∑p vƒÉn b·∫£n t∆∞∆°ng t·ª± s·ª≠ d·ª•ng MinHash + LSH
    
    Args:
        texts: List c√°c vƒÉn b·∫£n string
        num_perm: S·ªë l∆∞·ª£ng permutation trong MinHash
        jaccard_threshold: Ng∆∞·ª°ng Jaccard similarity
        k_shingles: K√≠ch th∆∞·ªõc k-shingles
    
    Returns:
        List c√°c tuple (doc_id_1, doc_id_2, jaccard_similarity)
    """
    
    if not texts or len(texts) < 2:
        print("‚ö†Ô∏è  Danh s√°ch vƒÉn b·∫£n kh√¥ng h·ª£p l·ªá")
        return []
    
    n_docs = len(texts)
    print(f"üîç MinHash: X·ª≠ l√Ω {n_docs} vƒÉn b·∫£n (num_perm={num_perm}, k={k_shingles})")
    
    # B∆∞·ªõc 1: T·∫°o MinHash cho m·ªói vƒÉn b·∫£n
    print("   B∆∞·ªõc 1: T·∫°o MinHash signatures...")
    minhashes = []
    
    for idx, text in enumerate(tqdm(texts, desc="   MinHash")):
        shingles = create_shingles(text, k=k_shingles)
        
        m = MinHash(num_perm=num_perm)
        for shingle in shingles:
            m.update(shingle.encode('utf-8'))
        
        minhashes.append(m)
    
    # B∆∞·ªõc 2: LSH ƒë·ªÉ t√¨m candidates
    print("   B∆∞·ªõc 2: LSH to find candidate pairs...")
    lsh = MinHashLSH(threshold=jaccard_threshold, num_perm=num_perm)
    
    for idx, m in enumerate(minhashes):
        lsh.insert(f"doc_{idx}", m)
    
    # B∆∞·ªõc 3: T√¨m candidate pairs
    candidate_pairs = set()
    for idx, m in enumerate(minhashes):
        candidates = lsh.query(m)
        for candidate_id in candidates:
            candidate_idx = int(candidate_id.split('_')[1])
            if idx < candidate_idx:
                candidate_pairs.add((idx, candidate_idx))
    
    # B∆∞·ªõc 4: Ki·ªÉm tra chi ti·∫øt t·ª´ng c·∫∑p
    print(f"   B∆∞·ªõc 3: X√°c nh·∫≠n {len(candidate_pairs)} candidate pairs...")
    
    results = []
    for (i, j) in tqdm(candidate_pairs, desc="   Verify"):
        jaccard_sim = minhashes[i].jaccard(minhashes[j])
        
        if jaccard_sim >= jaccard_threshold:
            results.append((i, j, jaccard_sim))
    
    # S·∫Øp x·∫øp theo similarity gi·∫£m d·∫ßn
    results.sort(key=lambda x: x[2], reverse=True)
    
    print(f"‚úì T√¨m ƒë∆∞·ª£c {len(results)} c·∫∑p t∆∞∆°ng t·ª± (ng∆∞·ª°ng: {jaccard_threshold})")
    return results


if __name__ == '__main__':
    # Test
    test_texts = [
        "Vi·ªát Nam l√† m·ªôt n∆∞·ªõc x√£ h·ªôi ch·ªß nghƒ©a",
        "Vi·ªát Nam l√† m·ªôt n∆∞·ªõc x√£ h·ªôi ch·ªß nghƒ©a v·ªõi th·ªß ƒë√¥ H√† N·ªôi",
        "H√† N·ªôi l√† th·ªß ƒë√¥ c·ªßa Vi·ªát Nam",
        "Python l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn",
    ]
    
    results = find_duplicates_minhash(test_texts, jaccard_threshold=0.3)
    
    print("\nK·∫øt qu·∫£:")
    for i, j, sim in results:
        print(f"  ({i}, {j}): {sim:.4f} - '{test_texts[i][:50]}...' <-> '{test_texts[j][:50]}...'")